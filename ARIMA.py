# -*- coding: utf-8 -*-
"""ARIMA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HltBJx-w3QTCLShDv6-ESpfYHFYHUi35
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
#%matplotlib inline
import seaborn as sns

cities = pd.read_csv('GlobalLandTemperaturesByCity.csv')
cities.head()
cities.shape

usa = cities[cities['Country'] == 'United States']
usa.shape

data = ['Alexandria', 'Albuquerque', 'Abilene']
data2 = usa[usa['City'].isin(data)]
data2.head()

data2 = data2[['dt', 'AverageTemperature']]
data2.head()
data2.columns = ['Date', 'Temp']
data2.head()

data2['Date'] = pd.to_datetime(data2['Date'])
data2.isna().sum()
data2.shape
data2.set_index('Date', inplace=True)
data2.head()
data2 = data2['2003':'2013']

sns.lineplot(x=data2.index, y=data2['Temp'])

from statsmodels.tsa.stattools import adfuller
test_result = adfuller(data2['Temp'])
test_result

def adfuller_test(Temp):
  result = adfuller(Temp)
  labels = ['ADF Test Statistics', 'p-value', 'flags used', 'Number of observations used']
  for value, label in zip(result, labels):
    print(label+' : '+ str(value))
  if result[1] < 0.05:
    print('Data is STATIONARY and has no unit root')
  else:
    print('Data is NON-STATIONARY and has no unit root')

adfuller_test(data2['Temp'])

df = data2.copy()
df.head()

df['first_temp_diff'] = df['Temp'] - df['Temp'].shift(12)
df.head(15)
#IF THE AUTOCORRLEATION PLOT OF DATASET DEGRADES FAST LIKE LINEARLY, THE DATASET IS STATIONARY, OTHERWISE NON-STATIONARY
adfuller_test(df['first_temp_diff'][12:]) # FIRST WAY to drop NANs
adfuller_test(df['first_temp_diff'].dropna()) # SECOND WAY to drop NANs

sns.lineplot(x=df.index, y=df['first_temp_diff'])
df['first_temp_diff'].plot(figsize=(25, 12))

data2['month'] = data2.index.month
data2['year'] = data2.index.year
data2.head()

pivot = data2.pivot_table(values='Temp', index='month', columns='year')
print(pivot)

pivot.plot(figsize=(16,5))
plt.legend().remove()
plt.xlabel('Month')
plt.ylabel('Temperature')

monthly_seasonality = pivot.mean(axis=1)
monthly_seasonality.plot(figsize=(16,5))

df = df[['first_temp_diff']]
df.dropna(inplace=True)
df.head()

df['first_temp_diff'].rolling(window=5).mean()
value = pd.DataFrame(df['first_temp_diff'])
temp_df = pd.concat([value, df['first_temp_diff'].rolling(window=5).mean()], axis=1)
temp_df.columns = ['actual_temp', 'predicted_temp']
temp_df.head()

from sklearn.metrics import mean_squared_error

rmse = np.sqrt(mean_squared_error(temp_df['predicted_temp'][4:], temp_df['actual_temp'][4:]))
print(rmse)

#ARIMA

from statsmodels.tsa.arima_model import ARIMA
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

df.head()
plot_acf(df['first_temp_diff'])
#from graph we can see that q value that is nearer to the boundary is 3

plot_pacf(df['first_temp_diff'])
#from this graph we can see that p value we can take for ARIMA as q value is 2
df.shape

training_data = df[0:6000].values
test_data = df[6000:].values

arima = ARIMA(training_data, order=(2,1,3))
model = arima.fit()
predictions = model.forecast(steps=len(test_data))[0]
print(predictions)

rmse1 = np.sqrt(mean_squared_error(test_data, predictions))
print(rmse1)

#Cross-Validation

p_values = range(0,4)
q_values = range(0,4)
d_values = range(0,3)

import warnings
# evaluate an ARIMA model for a given order (p,d,q)
def evaluate_arima_model(X, arima_order):
  # prepare training dataset
  train_size = int(len(X) * 0.66)
  train, test = X[0:train_size], X[train_size:]
  history = [x for x in train]
  # make predictions
  predictions = list()
  for t in range(len(test)):
    model = ARIMA(history, order=arima_order)
    model_fit = model.fit()
    yhat = model_fit.forecast()[0]
    predictions.append(yhat)
    history.append(test[t])

  # calculate out of sample error
  rmse = np.sqrt(mean_squared_error(test, predictions))
  return rmse

def evaluate_models(df, p_values, d_values, q_values):
  df = df.astype('float32')
  best_score, best_cfg = float("inf"), None
  for p in p_values:
    for d in d_values:
      for q in q_values:
        order = (p,d,q)
        try:
          rmse = evaluate_arima_model(df, order)
          if rmse < best_score:
            best_score, best_cfg = rmse, order
          print('ARIMA%s RMSE=%.3f' % (order,rmse))
        except:
          continue
  print('Best ARIMA%s RMSE=%.3f' % (best_cfg, best_score))


warnings.filterwarnings("ignore")
evaluate_models(df.values, p_values, d_values, q_values)
#for p in p_values:
#  for d in d_values:
#    for q in q_values:
#      order = (p,d,q)
#      train = df[0:6000].values
#      test = df[6000:].values
#      predictions=[]
#      for i in range(len(test)):
#        try:
#          arima=ARIMA(train, order)
#          model=arima.fit()
#          pred=model.forecast()[0]
#          predictions.append(pred)
#          error=mean_squared_error(test, predictions)
#          print('MSE is {} with order {}'.format(error, order))
#        except:
#          continue